{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn import svm\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\n",
    "                    \"PassengerId\", \n",
    "                     \"Survived\",\n",
    "                     \"Pclass\",\n",
    "                     \"Name\",\n",
    "                     \"Sex\",\n",
    "                     \"Age\",\n",
    "                     \"SibSp\",\n",
    "                     \"Parch\",\n",
    "                     \"Ticket\",\n",
    "                     \"Fare\",\n",
    "                     \"Cabin\",\n",
    "                     \"Embarked\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ground_truth of data\n",
    "train = pd.read_csv(\"train.csv\",na_values=\"?\")\n",
    "test = pd.read_csv(\"test.csv\",na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copies of data\n",
    "train_copy = train.copy(deep=True)\n",
    "test_copy = test.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = [train_copy,test_copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "5          897       3                    Svensson, Mr. Johan Cervin    male   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
       "5  14.0      0      0     7538   9.2250   NaN        S  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_copy.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples=train_copy.shape[0]\n",
    "num_attributes = train_copy.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The titanic dataset contains 891 observations\n",
      "The titanic dataset contains 12 attributes\n"
     ]
    }
   ],
   "source": [
    "print (\"The titanic dataset contains {} observations\".format(num_samples))\n",
    "print (\"The titanic dataset contains {} attributes\".format(num_attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "----------\n",
      "Testing data\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Explore the data\n",
    "print(\"Training data\")\n",
    "print (train_copy.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print(\"Testing data\")\n",
    "print(test_copy.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean the data ~> get ride of NaN values\n",
    "for data in data_arr:\n",
    "    \n",
    "    data['Age'].fillna(data['Age'].median(),inplace=True)\n",
    "    data['Embarked'].fillna(data['Embarked'].mode()[0],inplace=True)\n",
    "    data['Fare'].fillna(data['Fare'].median(),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per the rules; we are supposed to drop cabin number from training set\n",
    "drop_columns = [\"PassengerId\",\"Cabin\",\"Ticket\"]\n",
    "train_copy.drop(drop_columns,axis = 1,inplace=True)\n",
    "test_copy.drop(drop_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "----------\n",
      "Testing data\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#double check the cleaning went as planned\n",
    "print(\"Training data\")\n",
    "print (train_copy.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print(\"Testing data\")\n",
    "print(test_copy.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(418, 8)\n"
     ]
    }
   ],
   "source": [
    "#train_copy still has the 'survived' column\n",
    "print(train_copy.shape)\n",
    "print(test_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data information\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null object\n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.7+ KB\n",
      "----------\n",
      "Testing data information\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      "Pclass      418 non-null int64\n",
      "Name        418 non-null object\n",
      "Sex         418 non-null object\n",
      "Age         418 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        418 non-null float64\n",
      "Embarked    418 non-null object\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 26.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#We will have to perform feature mapping on the 'object' type columns\n",
    "print(\"Training data information\")\n",
    "train_copy.info()\n",
    "print(\"-\"*10)\n",
    "print(\"Testing data information\")\n",
    "test_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#feature engineering\n",
    "for d in data_arr:\n",
    "    \n",
    "    #family size\n",
    "    d['FamilySize'] = d['SibSp'] + d['Parch'] + 1\n",
    "    d['IsAlone'] = 1\n",
    "    \n",
    "    d['IsAlone'].loc[d['FamilySize'] > 1] = 0\n",
    "    \n",
    "    #title\n",
    "    d[\"Title\"] = d['Name'].str.split(\",\",expand=True)[1].str.split('.',expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data information\n",
      " Mr              517\n",
      " Miss            182\n",
      " Mrs             125\n",
      " Master           40\n",
      " Dr                7\n",
      " Rev               6\n",
      " Col               2\n",
      " Major             2\n",
      " Mlle              2\n",
      " Lady              1\n",
      " Capt              1\n",
      " Mme               1\n",
      " Don               1\n",
      " Ms                1\n",
      " the Countess      1\n",
      " Jonkheer          1\n",
      " Sir               1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#double check the cleaning went as planned\n",
    "print(\"Training data information\")\n",
    "print(train_copy[\"Title\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr               True\n",
      " Miss             True\n",
      " Mrs              True\n",
      " Master           True\n",
      " Dr              False\n",
      " Rev             False\n",
      " Col             False\n",
      " Major           False\n",
      " Mlle            False\n",
      " Lady            False\n",
      " Capt            False\n",
      " Mme             False\n",
      " Don             False\n",
      " Ms              False\n",
      " the Countess    False\n",
      " Jonkheer        False\n",
      " Sir             False\n",
      "Name: Title, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#eliminate misc titles\n",
    "min_occurences = 10\n",
    "#creates a series indexed by title\n",
    "title_names  = (train_copy['Title'].value_counts() > min_occurences)\n",
    "print(title_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['Title'] = train_copy[\"Title\"].apply(lambda x: x if title_names.loc[x] == True else 'Misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the relevant titles...\n",
      " Mr        517\n",
      " Miss      182\n",
      " Mrs       125\n",
      " Master     40\n",
      "Misc        27\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the relevant titles...\")\n",
    "print(train_copy[\"Title\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's double check the data one more time...\n",
      "This is the trainning data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "Survived      891 non-null int64\n",
      "Pclass        891 non-null int64\n",
      "Name          891 non-null object\n",
      "Sex           891 non-null object\n",
      "Age           891 non-null float64\n",
      "SibSp         891 non-null int64\n",
      "Parch         891 non-null int64\n",
      "Fare          891 non-null float64\n",
      "Embarked      891 non-null object\n",
      "FamilySize    891 non-null int64\n",
      "IsAlone       891 non-null int64\n",
      "Title         891 non-null object\n",
      "dtypes: float64(2), int64(6), object(4)\n",
      "memory usage: 83.6+ KB\n",
      "----------\n",
      "This is the testing data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "Pclass        418 non-null int64\n",
      "Name          418 non-null object\n",
      "Sex           418 non-null object\n",
      "Age           418 non-null float64\n",
      "SibSp         418 non-null int64\n",
      "Parch         418 non-null int64\n",
      "Fare          418 non-null float64\n",
      "Embarked      418 non-null object\n",
      "FamilySize    418 non-null int64\n",
      "IsAlone       418 non-null int64\n",
      "Title         418 non-null object\n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's double check the data one more time...\")\n",
    "print(\"This is the trainning data...\")\n",
    "train_copy.info()\n",
    "print(\"-\"*10)\n",
    "print(\"This is the testing data...\")\n",
    "test_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_copy.shape)\n",
    "print(test_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert formats\n",
    "#age\n",
    "#title\n",
    "#embarked\n",
    "label = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_arr:\n",
    "    d[\"Title\"] = label.fit_transform(d['Title'])\n",
    "    d[\"Embarked\"] = label.fit_transform(d['Embarked'])\n",
    "    d[\"Age\"] = label.fit_transform(d['Age'])\n",
    "    d[\"Name\"] = label.fit_transform(d[\"Name\"])\n",
    "    d[\"Sex\"] = label.fit_transform(d[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After some feature mapping...\n",
      "This is the trainning data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "Survived      891 non-null int64\n",
      "Pclass        891 non-null int64\n",
      "Name          891 non-null int64\n",
      "Sex           891 non-null int64\n",
      "Age           891 non-null int64\n",
      "SibSp         891 non-null int64\n",
      "Parch         891 non-null int64\n",
      "Fare          891 non-null float64\n",
      "Embarked      891 non-null int64\n",
      "FamilySize    891 non-null int64\n",
      "IsAlone       891 non-null int64\n",
      "Title         891 non-null int64\n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 83.6 KB\n",
      "----------\n",
      "This is the testing data...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "Pclass        418 non-null int64\n",
      "Name          418 non-null int64\n",
      "Sex           418 non-null int64\n",
      "Age           418 non-null int64\n",
      "SibSp         418 non-null int64\n",
      "Parch         418 non-null int64\n",
      "Fare          418 non-null float64\n",
      "Embarked      418 non-null int64\n",
      "FamilySize    418 non-null int64\n",
      "IsAlone       418 non-null int64\n",
      "Title         418 non-null int64\n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 36.0 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"After some feature mapping...\")\n",
    "print(\"This is the trainning data...\")\n",
    "train_copy.info()\n",
    "print(\"-\"*10)\n",
    "print(\"This is the testing data...\")\n",
    "test_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      0\n",
       "FamilySize    0\n",
       "IsAlone       0\n",
       "Title         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      0\n",
       "FamilySize    0\n",
       "IsAlone       0\n",
       "Title         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (891, 12)\n",
      "Testing date shape: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data shape: {}\".format(train_copy.shape))\n",
    "print (\"Testing date shape: {}\".format(test_copy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train  = train_copy['Survived']\n",
    "train_copy.drop(['Survived'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping the 'Survived' column ...\n",
      "(891, 11)\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "print (\"After dropping the 'Survived' column ...\")\n",
    "print(train_copy.shape)\n",
    "print(test_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_copy.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to numpy.ndarrays\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_train_logreg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_test_logreg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_logreg = [0.1,1,10,100,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logreg_model(c, X_train, Y_train,penalty):\n",
    "    '''\n",
    "        Author: Kyle Ong\n",
    "        Date: 05/13/2018\n",
    "        \n",
    "        fits a sklearn.linear_model.LogisticRegression(penalty = penalty, C=c, solver='saga')\n",
    "        to X_train and Y_train\n",
    "        \n",
    "        c: type: float\n",
    "        penalty: type: string\n",
    "        X_train: type: numpy.ndarray\n",
    "        Y_train: type: numpy.ndarray\n",
    "    \n",
    "    '''\n",
    "    logreg = linear_model.LogisticRegression(penalty=penalty, C=c ,solver='saga')\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        \n",
    "        warnings.filterwarnings('ignore',category=ConvergenceWarning)\n",
    "        \n",
    "        try:\n",
    "            logreg.fit(X_train,Y_train)\n",
    "            \n",
    "            y_hat = logreg.predict(X_train)\n",
    "            acc_train = np.mean(Y_train == y_hat)\n",
    "            print(\"This is the trainning accuracy with {} loss and {} c_val: {}\".format(penalty,c, acc_train))\n",
    "            \n",
    "        except Warning as w:\n",
    "            print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the trainning accuracy with L1 loss and 100 c_val: 0.6734006734006734\n"
     ]
    }
   ],
   "source": [
    "logreg_model(100,X_train,Y_train,\"L1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_logistic_model_with(X_train,Y_train,params):\n",
    "    '''\n",
    "            Author: Kyle Ong\n",
    "            Date: 05/12/2018\n",
    "            \n",
    "            will train sklearn.linear_model.LogisticRegression(penalty = penalty, C=c_val,solver='saga) over params\n",
    "            \n",
    "            X_train: type: numpy.ndarray\n",
    "            Y_train: type: numpy.ndarray\n",
    "            params: type: dict: {penalty:[c_vals]}\n",
    "    '''\n",
    "    for k,v in params.items():\n",
    "        \n",
    "        penalty = k\n",
    "        acc_train_array = []\n",
    "\n",
    "        for c_val in v:\n",
    "            #this is baest coding skills\n",
    "            log_model = 1\n",
    "            if penalty.lower() == \"l1\" :\n",
    "                log_model = linear_model.LogisticRegression(penalty=penalty, C=c_val,solver='saga')\n",
    "            \n",
    "            elif penalty.lower() == 'l2':\n",
    "                log_model = linear_model.LogisticRegression( C=c_val)\n",
    "                \n",
    "            with warnings.catch_warnings():\n",
    "                \n",
    "                warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "                \n",
    "                try:\n",
    "                     #fit the model\n",
    "                    log_model.fit(X_train,Y_train)  \n",
    "                    #train the model\n",
    "                    Y_hat = log_model.predict(X_train)\n",
    "            \n",
    "                    train_acc = np.mean(Y_hat == Y_train)\n",
    "            \n",
    "                    acc_train_array.append(train_acc)\n",
    "                    print(\"Accuracy with {} loss and c_val {} : {}\".format(penalty,c_val,train_acc))\n",
    "                \n",
    "                except Warning as w:\n",
    "                    print (w)\n",
    "            \n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"L1\":[0.1,1,10,100],\n",
    "    \"L2\":[0.1,1,10,100]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with L1 loss and c_val 0.1 : 0.6734006734006734\n",
      "Accuracy with L1 loss and c_val 1 : 0.6734006734006734\n",
      "Accuracy with L1 loss and c_val 10 : 0.6734006734006734\n",
      "Accuracy with L1 loss and c_val 100 : 0.6734006734006734\n",
      "Accuracy with L2 loss and c_val 0.1 : 0.7968574635241302\n",
      "Accuracy with L2 loss and c_val 1 : 0.8069584736251403\n",
      "Accuracy with L2 loss and c_val 10 : 0.8069584736251403\n",
      "Accuracy with L2 loss and c_val 100 : 0.8058361391694725\n"
     ]
    }
   ],
   "source": [
    "train_logistic_model_with(X_train,Y_train,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply feature transformations!\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_transformed = poly.fit_transform(X_train)\n",
    "labels = X_train_transformed.shape[1]\n",
    "observations = X_train_transformed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transformed titanic dataset has 891 observations.\n",
      "The titanic dataset has 78 labels\n"
     ]
    }
   ],
   "source": [
    "print (\"The transformed titanic dataset has {} observations.\".format(observations))\n",
    "print(\"The titanic dataset has {} labels\".format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with L1 loss and c_val 0.1 : 0.6745230078563412\n",
      "Accuracy with L1 loss and c_val 1 : 0.6734006734006734\n",
      "Accuracy with L1 loss and c_val 10 : 0.6745230078563412\n",
      "Accuracy with L1 loss and c_val 100 : 0.6734006734006734\n",
      "Accuracy with L2 loss and c_val 0.1 : 0.8237934904601572\n",
      "Accuracy with L2 loss and c_val 1 : 0.8282828282828283\n",
      "Accuracy with L2 loss and c_val 10 : 0.8271604938271605\n",
      "Accuracy with L2 loss and c_val 100 : 0.8237934904601572\n"
     ]
    }
   ],
   "source": [
    "train_logistic_model_with(X_train_transformed,Y_train,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the trainning set into test and training set\n",
    "split = math.floor(num_samples*0.5)\n",
    "\n",
    "X_train_split = X_train[0 : split, :]\n",
    "X_test_split = X_train[split: , :  ]\n",
    "Y_train_split = Y_train[0:split]\n",
    "Y_test_split = Y_train[split: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training observations has shape: (445, 11)\n",
      "Training targets has shape: (445,)\n",
      "Testing observations has shape: (446, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training observations has shape: {}\".format(X_train_split.shape))\n",
    "print(\"Training targets has shape: {}\".format(Y_train_split.shape))\n",
    "print(\"Testing observations has shape: {}\".format(X_test_split.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_logistic_model_with(X_train,Y_train,X_test,Y_test,params):\n",
    "    '''\n",
    "            Author: Kyle Ong\n",
    "            Date 05/13/2018\n",
    "            \n",
    "            trains and tests linear_model.LogisticRegression()\n",
    "            \n",
    "            X_train:type: numpy.ndarray\n",
    "            Y_train: type: numpy.ndarray\n",
    "            X_test: type: numpy.ndarray\n",
    "            Y_test: type: numpy.ndarray\n",
    "            params: type: dict {penalty : [c_val]}\n",
    "    '''\n",
    "    for k,v in params.items():\n",
    "        \n",
    "        penalty = k\n",
    "        acc_train_array = []\n",
    "        acc_test_arr = []\n",
    "\n",
    "        for c_val in v:\n",
    "            #this is baest coding skills\n",
    "            log_model = 1\n",
    "            if penalty.lower() == \"l1\" :\n",
    "                log_model = linear_model.LogisticRegression(penalty=penalty, C=c_val,solver='saga')\n",
    "            \n",
    "            elif penalty.lower() == 'l2':\n",
    "                log_model = linear_model.LogisticRegression( C=c_val)\n",
    "               \n",
    "            #uncoment context manager in order to get the convergence warning!\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "                try:\n",
    "                     #fit the model\n",
    "                    log_model.fit(X_train,Y_train)  \n",
    "                \n",
    "                    #train the model\n",
    "                    Y_hat = log_model.predict(X_train)\n",
    "                    train_acc = np.mean(Y_hat == Y_train)\n",
    "                    acc_train_array.append(train_acc)\n",
    "                    print(\"Training() ~> Accuracy with {} loss and c_val {} : \\n{}\".format(penalty,c_val,train_acc))\n",
    "                \n",
    "                    #test the model\n",
    "                    Y_hat_test = log_model.predict(X_test)\n",
    "                    acc_test =np.mean(Y_test == Y_hat_test)\n",
    "                    acc_test_arr.append(acc_test)\n",
    "                    print(\"Testing ~> Accuracy with {} loss and c_val {}: \\n{}\".format(penalty,c_val,acc_test))\n",
    "                    \n",
    "                \n",
    "                except Warning as w:\n",
    "                    print(w)\n",
    "                    \n",
    "        plt.plot(v,acc_test_arr)\n",
    "        plt.xlabel('C values')\n",
    "        plt.ylabel('Test accuracy')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training() ~> Accuracy with L1 loss and c_val 0.1 : \n",
      "0.6629213483146067\n",
      "Testing ~> Accuracy with L1 loss and c_val 0.1: \n",
      "0.6748878923766816\n",
      "Training() ~> Accuracy with L1 loss and c_val 1 : \n",
      "0.6629213483146067\n",
      "Testing ~> Accuracy with L1 loss and c_val 1: \n",
      "0.6748878923766816\n",
      "Training() ~> Accuracy with L1 loss and c_val 10 : \n",
      "0.6629213483146067\n",
      "Testing ~> Accuracy with L1 loss and c_val 10: \n",
      "0.6748878923766816\n",
      "Training() ~> Accuracy with L1 loss and c_val 100 : \n",
      "0.6629213483146067\n",
      "Testing ~> Accuracy with L1 loss and c_val 100: \n",
      "0.6748878923766816\n",
      "Training() ~> Accuracy with L2 loss and c_val 0.1 : \n",
      "0.8044943820224719\n",
      "Testing ~> Accuracy with L2 loss and c_val 0.1: \n",
      "0.7825112107623319\n",
      "Training() ~> Accuracy with L2 loss and c_val 1 : \n",
      "0.8089887640449438\n",
      "Testing ~> Accuracy with L2 loss and c_val 1: \n",
      "0.7802690582959642\n",
      "Training() ~> Accuracy with L2 loss and c_val 10 : \n",
      "0.8157303370786517\n",
      "Testing ~> Accuracy with L2 loss and c_val 10: \n",
      "0.7869955156950673\n",
      "Training() ~> Accuracy with L2 loss and c_val 100 : \n",
      "0.8157303370786517\n",
      "Testing ~> Accuracy with L2 loss and c_val 100: \n",
      "0.7914798206278026\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHMaDnlpjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1147bb588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_logistic_model_with(X_train_split,Y_train_split,X_test_split,Y_test_split,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split_transformed = poly.fit_transform(X_train_split)\n",
    "X_test_split_transformed = poly.fit_transform(X_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 78)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_split_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with L1 loss and c_val 0.1 : 0.6539325842696629\n",
      "Accuracy with L1 loss and c_val 1 : 0.651685393258427\n",
      "Accuracy with L1 loss and c_val 10 : 0.6539325842696629\n",
      "Accuracy with L1 loss and c_val 100 : 0.6539325842696629\n",
      "Accuracy with L2 loss and c_val 0.1 : 0.8359550561797753\n",
      "Accuracy with L2 loss and c_val 1 : 0.8359550561797753\n",
      "Accuracy with L2 loss and c_val 10 : 0.8359550561797753\n",
      "Accuracy with L2 loss and c_val 100 : 0.8314606741573034\n"
     ]
    }
   ],
   "source": [
    "train_logistic_model_with(X_train_split_transformed,Y_train_split,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training() ~> Accuracy with L1 loss and c_val 0.1 : \n",
      "0.6539325842696629\n",
      "Testing ~> Accuracy with L1 loss and c_val 0.1: \n",
      "0.6636771300448431\n",
      "Training() ~> Accuracy with L1 loss and c_val 1 : \n",
      "0.6539325842696629\n",
      "Testing ~> Accuracy with L1 loss and c_val 1: \n",
      "0.6636771300448431\n",
      "Training() ~> Accuracy with L1 loss and c_val 10 : \n",
      "0.6539325842696629\n",
      "Testing ~> Accuracy with L1 loss and c_val 10: \n",
      "0.6636771300448431\n",
      "Training() ~> Accuracy with L1 loss and c_val 100 : \n",
      "0.6539325842696629\n",
      "Testing ~> Accuracy with L1 loss and c_val 100: \n",
      "0.6636771300448431\n",
      "Training() ~> Accuracy with L2 loss and c_val 0.1 : \n",
      "0.8292134831460675\n",
      "Testing ~> Accuracy with L2 loss and c_val 0.1: \n",
      "0.7892376681614349\n",
      "Training() ~> Accuracy with L2 loss and c_val 1 : \n",
      "0.8269662921348314\n",
      "Testing ~> Accuracy with L2 loss and c_val 1: \n",
      "0.7892376681614349\n",
      "Training() ~> Accuracy with L2 loss and c_val 10 : \n",
      "0.8359550561797753\n",
      "Testing ~> Accuracy with L2 loss and c_val 10: \n",
      "0.7959641255605381\n",
      "Training() ~> Accuracy with L2 loss and c_val 100 : \n",
      "0.8337078651685393\n",
      "Testing ~> Accuracy with L2 loss and c_val 100: \n",
      "0.7937219730941704\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEoJi4iIqJSwiIiISgmLiIio9P8BcnQqrDSaLT8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1147042e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_logistic_model_with(X_train_split_transformed,Y_train_split,X_test_split_transformed,Y_test_split,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's try support vector machines!\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_linear(c,X_train,Y_train,X_test,Y_test):\n",
    "    '''\n",
    "            Author: Kyle Ong\n",
    "            Date: 05/13/2018\n",
    "            \n",
    "            fits a svm.SVC(probability = False, kernel = 'linear', C = c) to X_train and Y_train\n",
    "            calculates the training and test accuracies \n",
    "            \n",
    "            c: type: int\n",
    "            X_train: numpy.ndarray\n",
    "            Y_train: numpy.ndarray\n",
    "            X_test: numpy.ndarray\n",
    "            Y_test: numpy.ndarray\n",
    "            \n",
    "            will ignore convergence warnings thrown by sklearn\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    linear = svm.SVC(probability=False, kernel='linear',C=c)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "        \n",
    "        try:\n",
    "\n",
    "            linear.fit(X_train,Y_train)\n",
    "            \n",
    "            Y_hat_train = linear.predict(X_train)\n",
    "            train_acc =np.mean(Y_hat_train == Y_train)\n",
    "            print(\"Training ~> This is the training accuracy with Linear kernel and c_val {}: {}\".format(c,train_acc))\n",
    "            \n",
    "            \n",
    "            Y_hat_test = linear.predict(X_test)\n",
    "            test_acc = np.mean(Y_hat_test == Y_test)\n",
    "            linear_test_acc.append(test_acc)\n",
    "            print(\"Testing ~> This is the testing accuracy with Linear kernel and c_val {}:  {}\".format(c,test_acc))\n",
    "        \n",
    "        except Warning as w:\n",
    "            print(w)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_vals = [0.1,1,10,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ~> This is the training accuracy with Linear kernel and c_val 0.1: 0.8\n",
      "Testing ~> This is the testing accuracy with Linear kernel and c_val 0.1:  0.773542600896861\n",
      "Training ~> This is the training accuracy with Linear kernel and c_val 1: 0.802247191011236\n",
      "Testing ~> This is the testing accuracy with Linear kernel and c_val 1:  0.7780269058295964\n",
      "Training ~> This is the training accuracy with Linear kernel and c_val 10: 0.8157303370786517\n",
      "Testing ~> This is the testing accuracy with Linear kernel and c_val 10:  0.7847533632286996\n",
      "Training ~> This is the training accuracy with Linear kernel and c_val 100: 0.8202247191011236\n",
      "Testing ~> This is the testing accuracy with Linear kernel and c_val 100:  0.7869955156950673\n"
     ]
    }
   ],
   "source": [
    "linear_test_acc = []\n",
    "for c in c_vals:\n",
    "    svm_linear(c,X_train_split,Y_train_split,X_test_split,Y_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'linear kernel test accuracies')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nat5CDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146172b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c_vals,linear_test_acc)\n",
    "plt.xlabel(\"C values\")\n",
    "plt.ylabel(\"linear kernel test accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ~> This is the training accuracy with Linear kernel and c_val 0.1: 0.8067415730337079\n",
      "Testing ~> This is the testing accuracy with Linear kernel and c_val 0.1:  0.7847533632286996\n"
     ]
    }
   ],
   "source": [
    "linear_test_acc_ = []\n",
    "for c in c_vals:\n",
    "    svm_linear(c,X_train_split_transformed,Y_train_split,X_test_split_transformed,Y_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_rbf(c,X_train,Y_train,X_test,Y_test,gamma):\n",
    "    '''\n",
    "        Author: Kyle Ong\n",
    "        Date: 05/13/2018\n",
    "        \n",
    "        will fit a svm.SVC(probability = False, kernel = 'rbf', gamma = gamma) to X_train and Y_train\n",
    "        will calculate the train accuracy\n",
    "        will calcuate the test accuracy\n",
    "        \n",
    "        c: type: int\n",
    "        X_train: numpy.ndarray\n",
    "        Y_train: numpy.ndarray\n",
    "        X_test: numpy.ndarray\n",
    "        Y_test: numpy.ndarray\n",
    "        gamma: int\n",
    "        \n",
    "        will ignore convergence warnings thrown by sklearn    \n",
    "    '''\n",
    "    \n",
    "    svm_rbf = svm.SVC(probability=False, kernel='rbf',gamma=gamma)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=ConvergenceWarning)\n",
    "        \n",
    "        try:\n",
    "            svm_rbf.fit(X_train,Y_train)\n",
    "            \n",
    "            Y_hat_train = svm_rbf.predict(X_train)\n",
    "            train_acc = np.mean(Y_hat_train == Y_train)\n",
    "            print(\"This is the trainning accuracy with  Radial Basis Kernel and c_val {} and gamma {} : {}\".format(c,gamma,train_acc))\n",
    "            \n",
    "            Y_hat_test = svm_rbf.predict(X_test)\n",
    "            test_acc = np.mean(Y_hat_test == Y_test)\n",
    "            print(\"This is the testing accuracy with  Radial Basis Kernel and c_val {} and gamma {} : {}\".format(c,gamma,test_acc))\n",
    "            rbf_test_acc.append(test_acc)\n",
    "            \n",
    "        except Warning as w:\n",
    "            print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    0.1: [0.1,1,10,100],\n",
    "    1 :  [0.1,1,10,100],\n",
    "    10 :  [0.1,1,10,100],\n",
    "    100 :  [0.1,1,10,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in params.items():\n",
    "    \n",
    "    rbf_test_acc = []\n",
    "    c_val = k\n",
    "    \n",
    "    for gamma in v:\n",
    "        svm_rbf(c_val,X_train_split,Y_train_split,X_test_split,Y_test_split,gamma)\n",
    "        \n",
    "    plt.plot(v,rbf_test_acc)\n",
    "    plt.xlabel(\"C Value\")\n",
    "    plt.ylabel(\"Test accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in params.items():\n",
    "    \n",
    "    rbf_test_acc = []\n",
    "    c_val = k\n",
    "    \n",
    "    for gamma in v:\n",
    "        svm_rbf(c_val,X_train_split_transformed,Y_train_split,X_test_split_transformed,Y_test_split,gamma)\n",
    "        \n",
    "    plt.plot(v,rbf_test_acc)\n",
    "    plt.xlabel(\"C Value\")\n",
    "    plt.ylabel(\"Test accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_poly(X_train,Y_train,X_test,Y_test,c_val,degree):\n",
    "    '''\n",
    "        Author: Kyle Ong\n",
    "        Date: 03/16/2018\n",
    "        \n",
    "        X_train : type: numpy.ndarray\n",
    "        Y_train : type: numpy.ndarray\n",
    "        X_test: type: numpy.ndarray\n",
    "        Y_test: type: numpy.ndarray\n",
    "        c_val : type: int\n",
    "        degree : type: int\n",
    "        \n",
    "        will train a sklearn.svm.SVC(probability = False, kernel = \"poly\", degree=degree ) on X_train, Y_train\n",
    "        will calculate accuracy for X_train and X_test\n",
    "        will ignore convergence warnings thrown by sklearn\n",
    "    '''\n",
    "    \n",
    "    svm_poly = svm.SVC(probability = False, kernel = \"poly\", C=c_val,degree=degree)\n",
    "    svm_poly.fit(X_train,Y_train)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        \n",
    "        warnings.filterwarnings('ignore',category=ConvergenceWarning)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            Y_hat_train = svm_poly.predict(X_train)\n",
    "            train_acc = np.mean(Y_hat_train == Y_train)\n",
    "            print(\"This is the trainning accuracy with polynomial kernel and {} degree and {} c_val: {}\".format(degree,c_val,train_acc))\n",
    "            \n",
    "            Y_hat_test = svm_poly.predict(X_test)\n",
    "            test_acc = np.mean(Y_hat_test == Y_test)\n",
    "            print(\"This is the testing accuracy with polynomial kernel and {} degree and {} c_val: {}\".format(degree,c_val,test_acc))\n",
    "            \n",
    "        except Warning as w:\n",
    "            print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "        1:[0.1,1,10,100],\n",
    "        2:[0.1,1,10,100],\n",
    "        3:[0.1,1,10,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in params.items():\n",
    "    d = k\n",
    "    for c in v:\n",
    "        svm_poly(X_train_split,Y_train_split,X_test_split,Y_test_split,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in params.items():\n",
    "    d = k\n",
    "    for c in v:\n",
    "        svm_poly(X_train_split_transformed,Y_train_split,X_test_split_transformed,Y_test_split,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
